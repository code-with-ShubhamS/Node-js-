UTF => Unicode Transformation Format.In this we encode our code


The main difference between UTF-8, UTF-16, and UTF-32 is the number of bits used to encode a Unicode character:

UTF-8: Uses 8, 16, 24, or 32 bits (1â€“4 bytes) to encode a character. UTF-8 is compatible with ASCII and is used to store almost every web page.

UTF-16: Uses 16 or 32 bits to encode a character. UTF-16 uses 2 bytes per character. 

UTF-32: Uses 32 bits to encode a character. UTF-32 uses 4 bytes per character




xxd -b Random.txt